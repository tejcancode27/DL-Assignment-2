# -*- coding: utf-8 -*-
"""Q2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IEHJYDqeFDRAWXaHi34Kvm9ZJzZLy6Vv
"""

# Install required dependencies
!pip install transformers datasets tqdm torch torchvision torchaudio

# Import necessary libraries
import os
from datasets import Dataset
from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments
import kagglehub
import torch

# Set up for efficient use
os.environ["WANDB_DISABLED"] = "true"  # Disable wandb to avoid unnecessary tracking

# Function to download the dataset using kagglehub
def download_poetry_dataset():
    download_path = kagglehub.dataset_download("paultimothymooney/poetry")
    print(f"Dataset downloaded to: {download_path}")
    return download_path

# Function to load text files and collect lyrics
def load_lyrics_from_files(dataset_path):
    lyrics_files = [
        'kanye.txt', 'paul-simon.txt', 'radiohead.txt', 'missy-elliott.txt', 'bruce-springsteen.txt',
        'lin-manuel-miranda.txt', 'cake.txt', 'janisjoplin.txt', 'nicki-minaj.txt', 'alicia-keys.txt',
        'bieber.txt', 'amy-winehouse.txt', 'adele.txt', 'disney.txt', 'bob-marley.txt', 'rihanna.txt',
        'patti-smith.txt', 'lil-wayne.txt', 'Lil_Wayne.txt', 'eminem.txt', 'dickinson.txt', 'kanye-west.txt',
        'nickelback.txt', 'dj-khaled.txt', 'notorious-big.txt', 'nirvana.txt', 'michael-jackson.txt',
        'britney-spears.txt', 'dr-seuss.txt', 'r-kelly.txt', 'drake.txt', 'bob-dylan.txt', 'lady-gaga.txt',
        'Kanye_West.txt', 'prince.txt', 'joni-mitchell.txt', 'bjork.txt', 'dolly-parton.txt', 'bruno-mars.txt',
        'blink-182.txt', 'johnny-cash.txt', 'notorious_big.txt', 'al-green.txt', 'nursery_rhymes.txt',
        'ludacris.txt', 'leonard-cohen.txt', 'jimi-hendrix.txt', 'beatles.txt', 'lorde.txt'
    ]

    all_lyrics = []
    for filename in lyrics_files:
        file_path = os.path.join(dataset_path, filename)
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                lyrics = file.read().strip()
                if lyrics:
                    all_lyrics.append(lyrics)
        except Exception as e:
            print(f"Error reading {filename}: {e}")

    print(f"Loaded {len(all_lyrics)} song lyrics.")
    return all_lyrics

# Function to preprocess and tokenize the lyrics
def preprocess_and_tokenize(lyrics, tokenizer):
    def tokenize_function(batch):
        encoding = tokenizer(batch["text"], truncation=True, padding="max_length", max_length=512)
        encoding["labels"] = encoding["input_ids"].copy()  # Language modeling: labels = input_ids
        return encoding

    lyrics_dataset = Dataset.from_dict({"text": lyrics})
    split_data = lyrics_dataset.train_test_split(test_size=0.1)
    tokenized_data = split_data.map(tokenize_function, batched=True, remove_columns=["text"])
    return tokenized_data

# Function to set up the GPT-2 model and tokenizer
def setup_model():
    model_name = "gpt2"
    tokenizer = GPT2Tokenizer.from_pretrained(model_name)
    tokenizer.pad_token = tokenizer.eos_token  # GPT-2 has no pad token by default
    model = GPT2LMHeadModel.from_pretrained(model_name)
    return model, tokenizer

# Function to configure the Trainer for fine-tuning
def configure_trainer(model, tokenized_data):
    training_args = TrainingArguments(
        output_dir="./model_output",
        overwrite_output_dir=True,
        num_train_epochs=3,
        per_device_train_batch_size=2,
        save_steps=500,
        save_total_limit=2,
        logging_dir="./logs",
        logging_steps=100,
        report_to="none"  # Disable external logging tools like wandb
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_data["train"],
        eval_dataset=tokenized_data["test"]
    )
    return trainer

# Function to fine-tune the model
def fine_tune_model(trainer):
    print("Starting model fine-tuning...")
    trainer.train()

# Function to generate lyrics from a prompt
def generate_lyrics(model, tokenizer, prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    generated_output = model.generate(
        **inputs,
        max_length=100,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        temperature=0.9,
        top_k=50,
        top_p=0.95,
        do_sample=True,
        early_stopping=True
    )

    print("\nðŸŽµ Generated Lyrics ðŸŽµ\n")
    print(tokenizer.decode(generated_output[0], skip_special_tokens=True))

# Main function to run everything
def main():
    # Step 1: Download dataset
    dataset_path = download_poetry_dataset()

    # Step 2: Load the lyrics
    lyrics = load_lyrics_from_files(dataset_path)

    # Step 3: Set up tokenizer and model
    model, tokenizer = setup_model()

    # Step 4: Preprocess and tokenize the lyrics
    tokenized_data = preprocess_and_tokenize(lyrics, tokenizer)

    # Step 5: Configure the Trainer
    trainer = configure_trainer(model, tokenized_data)

    # Step 6: Fine-tune the model
    fine_tune_model(trainer)

    # Step 7: Generate lyrics with a sample prompt
    prompt = "The night was dark and full of stars"
    generate_lyrics(model, tokenizer, prompt)

    # Step 8: Save the fine-tuned model and tokenizer
    model.save_pretrained("./fine_tuned_model")
    tokenizer.save_pretrained("./fine_tuned_model")

if __name__ == "__main__":
    main()